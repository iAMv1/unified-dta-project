# Combined DeepDTAGen + DoubleSG-DTA + ESM-2 Configuration
# ========================================================

# Model Architecture Configuration
model:
  name: "CombinedDTAModel"
  
  # ESM-2 Configuration
  esm:
    model_name: "facebook/esm2_t8_8M_UR50D"
    embedding_dim: 320  # esm2_t8_8M_UR50D embedding dimension
    freeze_initial: true
    fine_tune_layers: 4  # Number of top layers to fine-tune
    
  # Drug Encoder Configuration  
  drug_encoder:
    # Graph Encoder (from DeepDTAGen)
    graph_encoder:
      node_features: 78
      hidden_dim: 256
      num_layers: 3
      dropout: 0.2
      
    # GIN Layers (from DoubleSG-DTA)
    gin_layers:
      num_layers: 5
      hidden_dim: 256
      dropout: 0.1
      
    # SENet Enhancement
    senet:
      reduction_ratio: 16
      
  # Protein Encoder Configuration
  protein_encoder:
    # Hybrid ESM-2 + Traditional
    hybrid_dim: 512
    traditional_embedding_dim: 128
    
    # Gated CNN (from DeepDTAGen)
    gated_cnn:
      num_filters: 32
      filter_sizes: [4, 6, 8]
      hidden_dim: 256
      
  # Attention Configuration
  attention:
    # Cross Multi-head Attention (from DoubleSG-DTA)
    num_heads: 8
    hidden_dim: 256
    dropout: 0.1
    
  # Output Heads
  prediction_head:
    hidden_dims: [1024, 512, 256]
    dropout: 0.3
    
  generation_head:
    vocab_size: 65  # SMILES vocabulary size
    max_length: 100
    num_layers: 6
    num_heads: 8
    hidden_dim: 256

# Training Configuration
training:
  # Phase 1: Frozen ESM-2
  phase1:
    epochs: 50
    batch_size: 32
    learning_rate: 1e-3
    weight_decay: 1e-4
    
  # Phase 2: ESM-2 Fine-tuning  
  phase2:
    epochs: 30
    batch_size: 16
    learning_rate: 1e-4
    esm_lr: 1e-5
    weight_decay: 1e-4
    
  # Phase 3: Full Model + Generation
  phase3:
    epochs: 20
    batch_size: 16
    learning_rate: 5e-5
    weight_decay: 1e-4

# Data Configuration
data:
  datasets: ["kiba", "davis", "bindingdb"]
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  
  # ESM-2 Tokenization
  max_protein_length: 1000
  
  # Drug Processing
  max_smiles_length: 100
  
# Loss Configuration
loss:
  affinity_weight: 1.0
  generation_weight: 0.5
  kl_weight: 0.1

# Hardware Configuration
device:
  use_cuda: true
  mixed_precision: true
  num_workers: 4
